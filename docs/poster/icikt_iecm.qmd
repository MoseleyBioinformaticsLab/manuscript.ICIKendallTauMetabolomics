---
title: "Information-Content-Informed Kendall-tau Correlation Methodology: Interpreting Missing Values as Useful Information"
citeproc: true
bibliography: icikt_references.json
csl: minimal_citation.csl
format:
  poster-typst: 
    size: "38x54"
    poster-authors: "R.M. Flight, P. Bhatt, H.N.B. Moseley"
    departments: "University of Kentucky Markey Cancer Center"
    institution-logo: "./images/ukmarkeylogo.png"
    footer-text: "IECM 2025"
    footer-url: "https://moseleybioinformaticslab.github.io/ICIKendallTau"
    footer-emails: "robert.flight@uky.edu"
    footer-color: "ebcfb2"
    keywords: ["Missing Not At Random", "Left-Censored", "Correlation"]
    keep-typ: true
---

# Missing Values in Metabolomics Data Not Random

Metabolomics data can contain a large amount of missing values, regardless of whether the metabolites are measured using mass-spectrometry (MS) or nuclear magnetic resonance (NMR), with examples from metabolomics workbench ranging from 0.01 - 90% missing values for MS and 1 - 26% missing values for NMR experiments, respectively (@fig-ranks (A)).
Using a binomial test for missing not at random (MNAR) due to left-censoring, we find that after adjusting for multiple testing, 235 of 242 experiments have a p-value < 0.05.

Calculating the median rank of metabolites, and the number of missing samples, we can see there is an inverse relationship between the number of samples a metabolite is missing from and the minimum value of the median rank (@fig-ranks B & C).
Over all the datasets, the correlation of rank to number of missing is overwhelmingly negative, with a few datasets with positive correlations that we suspect have incorrectly or insufficiently defined subject sample factors (@fig-ranks C).

![**A**: Percentage of values missing in MS and NMR datasets. **B**: Number of samples a metabolite is missing in vs the median rank (black) or minimum median rank (red) of the metabolite in the group of samples. **C**: Kendall-tau correlations of the median and minimum median rank to the number of samples a metabolite is missing from across all datasets.](./images/missingness_stuff.png){#fig-ranks}

The most likely reason for this degree of missingness and the inverse correlation of minimum rank with number of missing values is due to metabolites being below the detectable limit of the detector being used to measure the metabolites, or left-censoring of the data.

Correlation of both metabolites and samples is frequently undertaken in metabolomics studies for many different purposes, including the generation of metabolite-metabolite interaction networks, and sample-sample pairwise correlations to highlight biological and batch groups, or determine possible outliers prior to subsequent analysis.
However, correlation measures are severely impacted by the presence of missing values.

# Missingness as Useful Information

Given that the missingness is MNAR, and that it seems largely due to left-censoring in analytical instrumentation, we believe that the missingness therefore encodes useful information. 
To make use of this information, we propose the **information-content-informed Kendall-tau** (ICI-Kt) methodology.
Kendall-tau correlation is the easiest correlation to manipulate due to the way it encodes the ranks through pairwise comparisons of the ranks of data points by concordance and discordance of the **pairs** of data points.
In this case, a pair are any two x-y points, $x_i, y_i$ and $x_j, y_j$, with $i \neq j$, composed from two joint random variables X and Y, where $x_i$ represents the *ith value* in X and $y_i$ represents the *ith value* in Y.
In a metabolomics context, X and Y can represent metabolite abundance vectors for two experimental samples or two specific metabolites across a set of samples.

* Concordant:  $x_i > x_j \text{and} y_i > y_j \| x_i < x_j \text{and} y_i < y_j$
* Discordant:  $x_i > x_j \text{and} y_i < y_j \| x_i < x_j  \text{and} y_i > y_j$

$$\tau_b = \frac{n_{concordant} - n_{discordant}}{\sqrt{(n_{tot} - n_{xtie})(n_{tot} - n_{ytie})}}$$

where $n_{concordant}$ is the number of concordant pairs, $n_{discordant}$ is the number of discordant pairs, $n_{tot}$ is the total number of pairs, $n_{xtie}$ are the number of tied values in X, and $n_{ytie}$ are the number of paired values in Y. 
When we consider that most missingness is due to left-censorship, we can add to the definitions of concordant and discordant pairs that incorporate missingness, treating it as a *low* value.

* Concordant: $x_i > x_j \text{and} y_i \text{&} !y_j \| x_i < x_j \text{and} !y_i \text{&} y_j \| x_i \text{&} !x_j \text{and} y_i > y_j \| !x_i \text{&} x_j \text{and} y_i < y_j \| x_i \text{&} !x_j \text{and} y_i \text{&} !y_j \| !x_i \text{&} x_j \text{and} !y_i \text{&} y_j$ 

* Discordant: $x_i > x_j \text{and} !y_i \text{&} y_j \| x_i < x_j \text{and} y_i \text{&} !y_j \| x_i \text{&} !x_j \text{and} y_i < y_j \| !x_i \text{&} x_j \text{and} y_i > y_j \| x_i \text{&} !x_j \text{and} !y_i \text{&} y_j || !x_i \text{&} x_j \text{and} y_i \text{&} !y_j$

In our special case of missing data, we can add the ties that result from $(x_i=\text{NA}, x_j=\text{NA})$ and $(y_i=\text{NA}, y_j=\text{NA})$ to $n_{xtie}$ and $n_{ytie}$ [@kendall_treatment_ties_1945; @kendall_rankcorrelationbook_1948].

We can also consider commonly missing values in X and Y specially as well.
In the first instance, we remove those x-y points where **both values** are missing.
We refer to this case as the "local" ICI-Kt correlation.
It is most appropriate for the comparison of only two experimental samples, where we are concerned with what values are present in the two experimental samples, with the odd case of missingness.

The other case, where we leave ties resulting from points with missing X and Y, we refer to as the "global" ICI-Kt correlation.
In this case, every single correlation over multiple comparisons with the same set of features will consider the same number of pair comparisons.
This is useful when analyzing and interpreting correlations from a large number of experimental samples, not just two samples.

As an addition to the correlation value, we also calculate the *completeness* between any two samples.
We first measure the number of entries missing in either of the samples being compared, and subtract that from the total number of features in the samples.
This defines how many features are potentially *complete* between the two samples.
This number, over the total number of features defines the *completeness* fraction.

$$completness = \frac{n_{feat} - N (miss_i \cup miss_j)}{n_{feat}}$$

where for any two samples *i* and *j*, $n_{feat}$ is the total number of features or entries, and $miss_i \cup miss_j$ are the features missing in either sample *i* or *j*, with $N$ being the total number of missing entries in either sample *i* or *j*.

# MNAR vs MAR

@fig-mnar-mar demonstrates the effect of introducing MNAR versus MAR in five different measures of correlation, including the ICI-Kt, the normal Kendall-tau with *pairwise-complete-observations*, the normal Kendall-tau replacing missing with 0, Pearson with *pairwise-complete-observations*, and Pearson replacing missing with 0.
The ICI-Kt correlation demonstrates a slight increase from the starting 0.86 correlation value with growing left-centered missingness caused by a slight reinforcement of the correlation, while with **growing random missingness**, the ICI-Kt correlation drops precipitously due to the large increase in discordant pairs caused by the random missing values.
The normal Kendall tau correlation with pairwise complete has a small decrease in the correlation value with growing left-centered missingness caused by a loss of supporting pairs, while this correlation has a near constant average value with growing random missingness.
The normal Kendall tau correlation replacing missing with 0 has identical behavior to the ICI-Kt correlation.
In contrast to ICI-Kt, the Pearson correlation calculated using only pairwise complete entries is **practically constant** (i.e., range of 0.004 or less) over growing left-centered and random missingness.
When replacing missing values with zero, Pearson correlation demonstrates a small decrease in the correlation value with growing left-centered missingness due to the zero values causing some deviation from linearity. 
Pearson correlation drops precipitously with growing random missingness with a magnitude similar to the ICI-Kt and normal Kendall tau replacing missing with 0.
Overall, the ICI-Kt and the normal Kendall-tau replacing missing with zero have the desirable characteristics of maintaining the correlation with growing left-centered missing **while sharply dropping the correlation** with growing random missingness.
In a naive treatment of the left-centered missing data, if the values below the cutoff are set to missing followed by log-transforming the values and subsequently setting missing values to 0, then the Kendall tau correlation replacing missing with 0 will show some very odd patterns at low intensity cutoffs due to the introduction of discordant pairs.
Likewise, Pearson correlation replacing missing with 0 shows a parabolic effect with increasing missing values.

![Effect of introducing missing values from a cutoff (**A** & **B**) or randomly (**C**) on different measures of correlation, including ICI-Kt, Kendall with pairwise complete, Kendall replacing missing with 0, Pearson with pairwise complete, and Pearson replacing missing with 0. **A**: Missing values introduced by setting an increasing cutoff. **B**: Missing values introduced by setting an increasing cutoff, and then log-transforming the values before calculating correlation. **C**: Missing values introduced at random. For the random case, each sample of random positions was repeated 100 times. Pay attention to the different y-axis ranges across graphs, with **A** and **B** graphs having much smaller y-axis ranges compared to **C**.](./images/censored_value_plot.png){#fig-mnar-mar}


# Dynamic Range as a Cause of Missingness

Another way that missing values appear is due to changes in dynamic range between samples, as some samples have features with higher values, and the fixed dynamic range of the instrumentation results in features with lower values to be "missing" in those samples.
We created a set of 100 simulated samples with uniform noise on the log-scale, with relatively constant dynamic ranges, and introduced changes to the overall dynamic range using a random censor at varying levels.
Based on the number of values being censored, limits of 0.5, 1, and 1.5 were selected, representing low, medium and high variability of the dynamic range.

For each level of possible missingness introduced by changes to the dynamic range, correlation across all samples were calculated using all values (reference), as well as after missingness was added (trimmed), and using Pearson correlation with global imputation (Pearson Imputed), or ICI-Kt.
@fig-dynamic-range demonstrates that it is only as the number of missing values in one of the samples approaches 50% or more (500 of 1000 features) does the Pearson correlation with global imputation give correlation values closer to the known correlation with no missing values in any appreciable amount (points below the red lines in the top panels, and to the right of the red line in the histograms in the bottom panels).
Points above the lines with slopes of -1 and 1 indicate that the difference of reference - trimmed is smaller in the ICI-Kt correlations, and below the lines indicate the difference is larger in the ICI-Kt correlations.
This is further emphasized by the majority of the values are to the left of the line at 0 in the difference histograms.

![Top: Difference of reference - trimmed ICI-Kt correlation *vs* Pearson imputed using ½ the minimum value in the dataset. Low, med, and high indicate the level of variability in dynamic range, using 0.5, 1, and 1.5, respectively. Red lines indicate slope of -1 and 1. Color indicates the maximum number of missing values between the two samples being correlated. Bottom: Differences in the absolute value of reference - trimmed differences between ICI-Kt and Pearson imputed correlations.](./images/variable_dynamic_range.png){#fig-dynamic-range}

# Removing Outlier Samples

A common use for correlation is in calculating sample-sample correlations to verify groupings of samples and removal of possible outliers before further calculations [@flight_timecourseexploration_2010].
We evaluated the removal of outliers after sample-sample calculation using the various methods and then removal of any outlier samples based upon median correlations to all other samples in the same group, calculation of sample scores from principal component analysis (PCA), and then testing the sample scores of the most likely group PC using ANOVA to calculate the effect size $\eta^2$, and comparison with $\eta^2$ from the full dataset (*original*).
@fig-pca-outliers plots the ranks based on $\eta^2$, as well as the difference in $\eta^2$ after outlier removal compared to the full dataset.
@fig-pca-outliers does show that either ICI-Kt or the completeness variant are ranked first by effect size a majority of the time, followed closely by Pearson correlation using log-transformed values.
In terms of differences in effect size compared to the original data, ICI-Kt and completeness and Pearson using log-transformed values show very similar distributions overall. 

![**A**: Rank of $\eta^2$ after removal of outliers for each correlation method. **B**: Histogram of the difference of the correlation specific $\eta^2$ and the full dataset ($\eta^2_{org}). **C**: Zoomed version of **B** to highlight lower values.](./images/pca_outlier_plot.png){#fig-pca-outliers}

# Methods

## Data

**Repaired** Metabolomics Workbench (MW) analysis files were obtained for a large sample of the analyses available from MW.
For each analysis, we parsed the various data blocks to generate R compatible data.
For this work, we only kept analyses that had:

1. 200 or more metabolites measured;
1. Two or more subject sample factors with 4 or more replicates;
1. Contained missing values (parsing to numeric returned NA or 0);
1. Abundance data could be directly parsed to a matrix (some were lists ...);
1. Only one species was measured;
1. The sample IDs between subject sample factors and the metabolites data matched.

This resulted in 241 analyses, to which we added a previously published MS direct injection lipidomics dataset [@mitchellUntargetedLipidomicsNonSmall2021], for a total of **242** datasets.
Unique combinations of subject sample factors defined the sample **factors** used for grouping samples.

Prior to calculations, all metabolite values $\leq 0$ were set to R's missing indicator, `NA`, so that zeros and actually missing indicated values were treated identically, and missingness could be replaced with zero for some correlation calculations.

Metabolites present in at least one sample of each set of subject sample factors were kept for all further calculations.
Each sample was normalized using the median metabolite abundance in the sample.

## Correlation Methods

For each dataset, we calculated correlations using a variety of methods. In each dataset, there were either zero values or `NA` values to represent missingness.
To start, we replaced all zero values with `NA`, and then either left them as `NA` or changed them to zero as appropriate.

* ICI-Kendall-tau using `NA` (icikt); 
* and then scaled (multiplied) by a completeness metric (icikt_completeness);
* Kendall-tau using `NA`, and then using pairwise-complete-observations (kt);
* Pearson, with zeros replacing `NA`, using pairwise-complete-observations (pearson_base);
* Pearson, using `NA` and pairwise-complete-observations (pearson_no_zero).
* Pearson, with zeros replacing `NA`, and then a $log(x + 1)$ transform applied, using pairwise-complete-observations (pearson_log1p).
* Pearson, with zeros replacing `NA`, and then a $log(x)$ transform, and setting infinite values to `NA` values, using pairwise-complete-observations (PL).

## Detecting and Removing Possible Outliers

For outlier detection, median sample-sample correlations within the sample treatment (genotype, condition, etc) is calculated, and $log(1 - cor_{median})$ calculated to transform it into a score. Then outliers are determined using *grDevices::boxplot.stats*, which by default are at 1.5X the whiskers in a box-and-whisker plot.
As we are interested in only those correlations at the *low* end of correlation (becoming the high end after the subtraction and log-transform), we restrict to only those entries at the *high* end of the score distribution (using *visualizationQualityControl::determine_outliers* [@flightVisualizationQualityControlDevelopmentVisualization2021]).
This is equivalent to using the correlation component of the score described by Gierliński et al [-@gierlinski_statisticalmodels_2015] and setting the other component weights to zero.

## Principal Component Analysis of Outlier Removal

For the original data with all samples, and then after removing outliers using the median sample-sample correlations reported by each method, a value 1/2 the lowest observed value in the data was imputed to all missing values, *log* transformed, and principal component analysis (PCA) of the samples undertaken.
The scores of each sample on each PC were taken, and ANOVA and $\eta{^2}$ effect size of the sample scores against the sets of subject sample factor calculated.
The most likely PC representing the subject sample factors was defined as the PC with the lowest p-value from ANOVA using the full dataset with no outliers removed.
The unique $\eta^2$ from the ANOVA of each correlation method are determined, and ranked, therefore enabling tied rankings amongst the various correlation methods.

## Availability

ICI-Kt is available in the R package `ICIKendallTau` from https://moseleybioinformaticslab.github.io/ICIKendallTau and a python package `icikt` from https://pypi.org/project/icikt/.

## Bibliography